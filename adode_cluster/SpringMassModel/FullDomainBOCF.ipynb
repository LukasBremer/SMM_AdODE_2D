{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import jax and other libraries for computation\n",
    "import jax.numpy as jnp\n",
    "from jax import jit\n",
    "from jax.scipy.signal import convolve2d\n",
    "from jax.flatten_util import ravel_pytree\n",
    "from jax.experimental.ode import odeint\n",
    "from jax import tree_util\n",
    "import jax.random as random\n",
    "import numpy as np\n",
    "#for visulization\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# Set Palatino as the default font\n",
    "font = {'family': 'serif', 'serif': ['Palatino'], 'size': 20}\n",
    "plt.rc('font', **font)\n",
    "plt.rc('text', usetex=True)\n",
    "# import AdoptODE\n",
    "from adoptODE import train_adoptODE, simple_simulation, dataset_adoptODE\n",
    "#import the MSD mechanics\n",
    "from HelperAndMechanics import *\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_h5_structure(file_path):\n",
    "    '''Recursively lists all groups, datasets, and attributes in an HDF5 file'''\n",
    "    \n",
    "    def print_structure(name, obj):\n",
    "        indent = '  ' * name.count('/')\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            print(f\"{indent}üìÇ Group: {name}\")\n",
    "            # for key, value in obj.attrs.items():\n",
    "            #     print(f\"{indent}  ‚îî‚îÄ‚îÄ üè∑Ô∏è  Attribute: {key} = {value}\")\n",
    "        # elif isinstance(obj, h5py.Dataset):\n",
    "            # print(f\"{indent}üìÑ Dataset: {name} - shape: {obj.shape}, dtype: {obj.dtype}\")\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        print(f\"üìÅ HDF5 File: {file_path}\")\n",
    "        f.visititems(print_structure)\n",
    "\n",
    "def define_MSD_BOCF(**kwargs_sys):\n",
    "  disc_x, disc_y = kwargs_sys['disc_x'], kwargs_sys['disc_y']\n",
    "  dx, dy = kwargs_sys['len_x'] / disc_x, kwargs_sys['len_y'] / disc_y\n",
    "  N_sys = kwargs_sys['N_sys']\n",
    "\n",
    "  def d_dx(f):\n",
    "    return jnp.concatenate((jnp.zeros(\n",
    "        (1, disc_x)), f[1:] - f[:-1], jnp.zeros((1, disc_x))),\n",
    "                           axis=0)\n",
    "\n",
    "  def d_dy(f):\n",
    "    return jnp.concatenate((jnp.zeros(\n",
    "        (disc_y, 1)), f[:, 1:] - f[:, :-1], jnp.zeros((disc_y, 1))),\n",
    "                           axis=1)\n",
    "\n",
    "  def gradient(f):  #gradient of scalar field\n",
    "    gx = d_dx(f)\n",
    "    gy = d_dy(f)\n",
    "    return jnp.stack((gx, gy), axis=2)\n",
    "\n",
    "  # stencil5 = np.array([1/4,1/2,-1.5,1/2,1/4])\n",
    "  # distr5 = np.array([0.05,0.1,0.7,0.1,0.05])\n",
    "  # kernel = np.outer(distr5, stencil5/dz**2) + np.outer(stencil5/dx**2, distr5)\n",
    "  kernel = np.array([[1, 4, 1], [4, -20.0, 4], [1, 4, 1]]) / (\n",
    "      dx * dy * 6)  #np.array([[0,1,0],[1,-4,1.],[0,1,0]])/(dx*dy)\n",
    "\n",
    "  def laplace(f):  #laplace of scalar\n",
    "    f_ext = jnp.concatenate((f[0:1], f, f[-1:]), axis=0)\n",
    "    f_ext = jnp.concatenate((f_ext[:, 0:1], f_ext, f_ext[:, -1:]), axis=1)\n",
    "    return convolve2d(f_ext, kernel, mode='valid')\n",
    "\n",
    "  H = lambda x: jnp.heaviside(x, 0)\n",
    "\n",
    "  missing_params = {}\n",
    "  for key in kwargs_sys.keys():\n",
    "    if not key in [\n",
    "        'disc_x', 'disc_y', 'len_x', 'len_y', 'N_sys', 'Params_BOCF',\n",
    "        'puls_amp', 'puls_size', 'puls_reps', 'puls_dist', 'puls_num'\n",
    "    ] + kwargs_sys['Params_BOCF']:\n",
    "      missing_params[key] = kwargs_sys[key]\n",
    "\n",
    "  def tau_v_minus(u, ap):\n",
    "    return (1 - H(u - ap['theta_v_minus'])) * ap['tau_v_minus1'] + H(\n",
    "        u - ap['theta_v_minus']) * ap['tau_v_minus2']\n",
    "\n",
    "  def tau_w_minus(u, ap):\n",
    "    return ap['tau_w_minus1'] + (ap['tau_w_minus2'] - ap['tau_w_minus1']) * (\n",
    "        1 + jnp.tanh(ap['k_w_minus'] * (u - ap['u_w_minus']))) / 2\n",
    "\n",
    "  def tau_so(u, ap):\n",
    "    return ap['tau_so1'] + (ap['tau_so2'] - ap['tau_so1']) * (\n",
    "        1 + jnp.tanh(ap['k_so'] * (u - ap['u_so']))) / 2\n",
    "\n",
    "  def tau_s(u, ap):\n",
    "    return (1 - H(u - ap['theta_w'])\n",
    "            ) * ap['tau_s1'] + H(u - ap['theta_w']) * ap['tau_s2']\n",
    "\n",
    "  def tau_o(u, ap):\n",
    "    return (1 - H(u - ap['theta_o'])\n",
    "            ) * ap['tau_o1'] + H(u - ap['theta_o']) * ap['tau_o2']\n",
    "\n",
    "  def v_inf(u, ap):\n",
    "    return (1 - H(u - ap['theta_v_minus']))\n",
    "\n",
    "  def w_inf(u, ap):\n",
    "    return (1 - H(u - ap['theta_o'])) * (\n",
    "        1 - u / ap['tau_w_inf']) + H(u - ap['theta_o']) * ap['w_inf_star']\n",
    "\n",
    "  # D = kwargs_sys['D']\n",
    "  u0, v0, w0, s0 = kwargs_sys['u0'], kwargs_sys['v0'], kwargs_sys[\n",
    "      'w0'], kwargs_sys['s0']\n",
    "  puls_amp, puls_size, puls_num, puls_dist, puls_reps = kwargs_sys[\n",
    "      'puls_amp'], kwargs_sys['puls_size'], kwargs_sys['puls_num'], kwargs_sys[\n",
    "          'puls_dist'], kwargs_sys['puls_reps']\n",
    "\n",
    "  def J_fi(y, ap):\n",
    "    return -(y['v'] * H(y['u'] - ap['theta_v']) * (y['u'] - ap['theta_v']) *\n",
    "             (ap['u_u'] - y['u'])) / ap['tau_fi']\n",
    "\n",
    "  def J_so(y, ap):\n",
    "    return (y['u'] - ap['u_o']) * (1 - H(y['u'] - ap['theta_w'])) / tau_o(\n",
    "        y['u'], ap) + H(y['u'] - ap['theta_w']) / tau_so(y['u'], ap)\n",
    "\n",
    "  def J_si(y, ap):\n",
    "    return -H(y['u'] - ap['theta_w']) * y['w'] * y['s'] / ap['tau_si']\n",
    "\n",
    "  def du_dt(y, ap):\n",
    "    return ap['D'] * laplace(y['u']) - (J_fi(y, ap) + J_so(y, ap) +\n",
    "                                        J_si(y, ap))\n",
    "\n",
    "  def dv_dt(y, ap):\n",
    "    return (1 - H(y['u'] - ap['theta_v'])) * (\n",
    "        v_inf(y['u'], ap) - y['v']) / tau_v_minus(\n",
    "            y['u'], ap) - H(y['u'] - ap['theta_v']) * y['v'] / ap['tau_v_plus']\n",
    "\n",
    "  def dw_dt(y, ap):\n",
    "    return (1 - H(y['u'] - ap['theta_w'])) * (\n",
    "        w_inf(y['u'], ap) - y['w']) / tau_w_minus(\n",
    "            y['u'], ap) - H(y['u'] - ap['theta_w']) * y['w'] / ap['tau_w_plus']\n",
    "\n",
    "  def ds_dt(y, ap):\n",
    "    return (\n",
    "        (1 + jnp.tanh(ap['k_s'] *\n",
    "                      (y['u'] - ap['u_s']))) / 2 - y['s']) / tau_s(y['u'], ap)\n",
    "                      \n",
    "  def rescale_params(params):\n",
    "    params_scaled = {}\n",
    "    \n",
    "    for key in params.keys():\n",
    "        if key in kwargs_sys['Params_BOCF']:\n",
    "            if kwargs_sys[key]<1:\n",
    "                params_scaled[key] = params[key]\n",
    "            else:\n",
    "                params_scaled[key] = 10**params[key]\n",
    "        \n",
    "    return params_scaled\n",
    "  #for MSD\t   \n",
    "  @jit\n",
    "  def epsilon_T(u):\n",
    "    return 1 - 0.9*jnp.exp(-jnp.exp(-30*(jnp.abs(u) - 0.1)))\n",
    "  @jit\n",
    "  def eom(y, t, params, iparams, exparams):\n",
    "    all_params = {**rescale_params(params), **missing_params}\n",
    "    dudt = du_dt(y, all_params)\n",
    "    dvdt = dv_dt(y, all_params)\n",
    "    dwdt = dw_dt(y, all_params)\n",
    "    dsdt = ds_dt(y, all_params)\n",
    "    dTdt = 1/12.9*epsilon_T(y['u'])*(params['k_T']*jnp.abs(y['u'])-y['T'])\n",
    "    dx_dotdt = 1/12.9*1/params['m'] *  (force_field_active(y['x'],y['T'],params) + force_field_passive(y['x'],params) + force_field_struct(y['x'],y['T'],params) - y['x_dot'] * params['c_damp'])\n",
    "    dxdt = 1/12.9*y['x_dot']\n",
    "    return {'u': dudt, 'v': dvdt, 'w': dwdt, 's': dsdt,'T':dTdt,'x':dxdt,'x_dot':dx_dotdt}\n",
    "\n",
    "  @jit\n",
    "  def loss(ys, params, iparams, exparams, targets):\n",
    "    flat_fit = ravel_pytree(ys)[0]\n",
    "    flat_target = ravel_pytree(targets)[0]\n",
    "    return jnp.nanmean((flat_fit - flat_target)**2)\n",
    "\n",
    "  def gen_params():\n",
    "    params = {}\n",
    "    for key in kwargs_sys['Params_BOCF']:\n",
    "      if kwargs_sys[key]<1:\n",
    "        params[key] = kwargs_sys[key] * (0.5 + np.random.rand())\n",
    "      else:\n",
    "        params[key] = np.log10(kwargs_sys[key] * (0.5 + np.random.rand()))\n",
    "    for key in kwargs_sys['Params_MSD']:\n",
    "      params[key] = kwargs_sys[key] \n",
    "    return params, {}, {}\n",
    "\n",
    "  def gen_y0():\n",
    "    u = u0 * jnp.ones((disc_x, disc_y))\n",
    "    v = v0 * jnp.ones((disc_x, disc_y))\n",
    "    w = w0 * jnp.ones((disc_x, disc_y))\n",
    "    s = s0 * jnp.ones((disc_x, disc_y))\n",
    "    #initialize the mechanical part\n",
    "    size_mech = disc_x + 2* kwargs_sys['pad'] + 1\n",
    "    x_vals = np.linspace(0, size_mech-1,size_mech)\n",
    "    z_vals = np.linspace(0, size_mech-1,size_mech)\n",
    "    # Generate meshgrid for x and z\n",
    "    x_grid, z_grid = np.meshgrid(x_vals, z_vals)\n",
    "    xy_grid = jnp.array([x_grid, z_grid])\n",
    "    \n",
    "    y = {'u': u, 'v': v, 'w': w, 's': s,'T':jnp.zeros((disc_x, disc_y)),'x':xy_grid,'x_dot':jnp.zeros(xy_grid.shape)}\n",
    "    params_true = {}\n",
    "    for key in kwargs_sys['Params_BOCF']:\n",
    "      if kwargs_sys[key]<1:\n",
    "        params_true[key] = kwargs_sys[key]\n",
    "      else:\n",
    "        params_true[key] = np.log10(kwargs_sys[key])\n",
    "    for key in kwargs_sys['Params_MSD']:\n",
    "      params_true[key] = kwargs_sys[key] \n",
    "\n",
    "    solver = jit(lambda y: odeint(eom,\n",
    "                                  y,\n",
    "                                  np.array([0.0, puls_dist]),\n",
    "                                  params_true, {}, {},\n",
    "                                  atol=1e-4,\n",
    "                                  rtol=1e-4))\n",
    "    for i in range(puls_reps):\n",
    "      mask = np.zeros((disc_x, disc_y))\n",
    "      pos = np.round(\n",
    "          np.random.rand(puls_num, 2) *\n",
    "          np.array([disc_x - puls_size - 1, disc_y - puls_size - 1\n",
    "                    ])[np.newaxis]).astype(int)\n",
    "      for p in pos:\n",
    "        mask[p[0]:p[0] + puls_size,\n",
    "             p[1]:p[1] + puls_size] = puls_amp * np.ones(\n",
    "                 (puls_size, puls_size))\n",
    "      y['u'] = y['u'] + mask\n",
    "      sol = solver(y)\n",
    "      y = tree_util.tree_map(lambda x: x[-1], sol)\n",
    "    return y\n",
    "\n",
    "  return eom, loss, gen_params, gen_y0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining standard parameters:\n",
    "# This is a smaller system with adjusted parameters to allow spiral wave to occure in the smaller simulation domain.\n",
    "# For the full code with larger simulation domain is at the end of this notebook.\n",
    "\n",
    "kwargs_sys = {\n",
    "    'disc_x': 128,#512\n",
    "    'disc_y': 128,#512\n",
    "    'len_x': 128,\n",
    "    'len_y': 128,\n",
    "    'N_sys': 1,\n",
    "    'u_o': 0,\n",
    "    'u_u': 1.58,\n",
    "    'theta_v': 0.3,\n",
    "    'theta_w': 0.015,\n",
    "    'theta_v_minus': 0.015,\n",
    "    'theta_o': 0.006,\n",
    "    'tau_v_minus1': 60,\n",
    "    'tau_v_minus2': 1150,\n",
    "    'tau_v_plus': 1.4506,\n",
    "    'tau_w_minus1': 70,\n",
    "    'tau_w_minus2': 20,\n",
    "    'k_w_minus': 65,\n",
    "    'u_w_minus': 0.03,\n",
    "    'tau_w_plus': 280,\n",
    "    'tau_fi': 0.11,\n",
    "    'tau_o1': 6,\n",
    "    'tau_o2': 6,\n",
    "    'tau_so1': 43,\n",
    "    'tau_so2': 0.2,\n",
    "    'k_so': 2,\n",
    "    'u_so': 0.65,\n",
    "    'tau_s1': 2.7342,\n",
    "    'tau_s2': 3,\n",
    "    'k_s': 2.0994,\n",
    "    'u_s': 0.9087,\n",
    "    'tau_si': 2.8723,\n",
    "    'tau_w_inf': 0.07,\n",
    "    'w_inf_star': 0.94,\n",
    "    'u0': 0,\n",
    "    'v0': 1,\n",
    "    'w0': 1,\n",
    "    's0': 0,\n",
    "    'D': 0.1,\n",
    "    'Params_BOCF': ['u_s', 'u_so', 'k_so', 'tau_so1', 'tau_si', 'k_s', 'u_u', 'theta_v', 'D', 'tau_fi'], # These are the Parameters forgotten and recovered by training!\n",
    "    'Params_MSD': ['k_T','k_ij','k_ij_pad','k_j','k_a','k_a_pad','c_a','m','c_damp','n_0','l_0','spacing'],\n",
    "    'pad':10,\n",
    "    'puls_amp': 1.0,   #\n",
    "    'puls_size': 3,    #\n",
    "    'puls_reps': 30,   # These numbers define the initialization procedure\n",
    "    'puls_dist': 150,  #\n",
    "    'puls_num': 20     #\n",
    "}\n",
    "keys_MSD =['k_T','k_ij','k_ij_pad','k_j','k_a','k_a_pad','c_a','m','c_damp','n_0','l_0','spacing']\n",
    "N,size,params_true_MSD = read_config(['k_T','k_ij','k_ij_pad','k_j','k_a','k_a_pad','c_a','m','c_damp','n_0','l_0','spacing'],mode = 'chaos')\n",
    "params_true_MSD = dict(zip(keys_MSD,params_true_MSD))\n",
    "\n",
    "for key in params_true_MSD.keys():\n",
    "    kwargs_sys[key] = params_true_MSD[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u_s': 0.9087, 'u_so': 0.65, 'k_so': np.float64(0.3010299956639812), 'tau_so1': np.float64(1.6334684555795866), 'tau_si': np.float64(0.4582297982235676), 'k_s': np.float64(0.3220951928665501), 'u_u': np.float64(0.19865708695442263), 'theta_v': 0.3, 'D': 0.1, 'tau_fi': 0.11, 'k_T': 3.0, 'k_ij': 13.0, 'k_ij_pad': 23.0, 'k_j': 2.0, 'k_a': 9.0, 'k_a_pad': 23.0, 'c_a': 10.0, 'm': 1.0, 'c_damp': 15.0, 'n_0': 0.5, 'l_0': 1.0, 'spacing': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Following lines set up parameters and boundaries according to the parameters selected for training with 'Params_BOCF'\n",
    "params_true = {}\n",
    "lower_bound = {}\n",
    "for key in kwargs_sys['Params_BOCF']:\n",
    "  if kwargs_sys[key]<1:\n",
    "    params_true[key] = kwargs_sys[key]\n",
    "    lower_bound[key] = 0\n",
    "  else:\n",
    "    lower_bound[key] = -2\n",
    "    params_true[key] = np.log10(kwargs_sys[key])\n",
    "for key in kwargs_sys['Params_MSD']:\n",
    "  params_true[key] = params_true_MSD[key]\n",
    "  lower_bound[key] = 0\n",
    "\n",
    "print(params_true)\n",
    "# Setting up simulation domain\n",
    "N_times = 100\n",
    "t_evals = jnp.linspace(0, 50, N_times)\n",
    "\n",
    "# Specifying training properties\n",
    "reset_every = 34\n",
    "t_reset_idcs = tuple([\n",
    "    reset_every * i\n",
    "    for i in range(int(np.ceil((len(t_evals) - 1) / reset_every)))\n",
    "])\n",
    "kwargs_adoptODE = {\n",
    "    'epochs': 100,\n",
    "    'lr': 1e-2,\n",
    "    't_reset_idcs': t_reset_idcs,\n",
    "    'N_backups': 1,\n",
    "    'lower_b': lower_bound,\n",
    "    'atol': 1e-5,\n",
    "    'rtol': 1e-5,\n",
    "    'lr_decay':0.99\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a dataset via simulation\n",
    "dataset_BOCF = simple_simulation(define_MSD_BOCF,\n",
    "                            t_evals,\n",
    "                            kwargs_sys,\n",
    "                            kwargs_adoptODE,\n",
    "                            params=params_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18745402343483495f5cddc0a73716c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Frame', max=99)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c60e5de1f94864a62923d99f76e96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pad = 10\n",
    "dA = compute_dA(dataset_BOCF.ys['x'][0],1)\n",
    "# Function to update the plot\n",
    "def update_plot(frame):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # Create 2 side-by-side subplots\n",
    "    \n",
    "    # Plot dA_fit\n",
    "    im1 = axes[0].matshow(dataset_BOCF.ys['u'][0,frame], cmap='coolwarm')\n",
    "    # im1 = axes[0].matshow(dA_rec[frame, pad:-pad, pad:-pad], cmap='coolwarm', vmin=vmin, vmax=vmax)\n",
    "    axes[0].set_title(f\"reconstruction\")\n",
    "    \n",
    "    # Plot dA_sim\n",
    "    im2 = axes[1].matshow(dA[frame,pad:-pad,pad:-pad], cmap='coolwarm')\n",
    "    # im2 = axes[1].matshow(dA_sim[frame, pad:-pad, pad:-pad], cmap='coolwarm', vmin=vmin, vmax=vmax)\n",
    "    axes[1].set_title(f\"simulation\")\n",
    "    \n",
    "    # Add colorbars\n",
    "    # fig.colorbar(im1, ax=axes[0])\n",
    "    # fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive slider\n",
    "frame_slider = widgets.IntSlider(min=0, max=dataset_BOCF.ys['u'][0,:].shape[0]-1, step=1, value=0, description=\"Frame\")\n",
    "\n",
    "# Use interactive_output instead of interactive\n",
    "out = widgets.interactive_output(update_plot, {'frame': frame_slider})\n",
    "\n",
    "# Display slider and output\n",
    "display(frame_slider, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_AP(**kwargs_sys):\n",
    "  disc_x, disc_y = kwargs_sys['disc_x'], kwargs_sys['disc_y']\n",
    "  dx, dy = kwargs_sys['len_x'] / disc_x, kwargs_sys['len_y'] / disc_y\n",
    "  N_sys = kwargs_sys['N_sys']\n",
    "\n",
    "  def d_dx(f):\n",
    "    return jnp.concatenate((jnp.zeros(\n",
    "        (1, disc_x)), f[1:] - f[:-1], jnp.zeros((1, disc_x))),\n",
    "                           axis=0)\n",
    "\n",
    "  def d_dy(f):\n",
    "    return jnp.concatenate((jnp.zeros(\n",
    "        (disc_y, 1)), f[:, 1:] - f[:, :-1], jnp.zeros((disc_y, 1))),\n",
    "                           axis=1)\n",
    "\n",
    "  kernel = np.array([[1, 4, 1], [4, -20.0, 4], [1, 4, 1]]) / (\n",
    "      dx * dy * 6)  #np.array([[0,1,0],[1,-4,1.],[0,1,0]])/(dx*dy)\n",
    "\n",
    "  def laplace(f):  #laplace of scalar\n",
    "    f_ext = jnp.concatenate((f[0:1], f, f[-1:]), axis=0)\n",
    "    f_ext = jnp.concatenate((f_ext[:, 0:1], f_ext, f_ext[:, -1:]), axis=1)\n",
    "    return convolve2d(f_ext, kernel, mode='valid')\n",
    "\n",
    "  def epsilon(u,v,rp):\n",
    "    return rp['eps0']+rp['mu1']*v/(u+rp['mu2'])\n",
    "\n",
    "  def eom(y, t, params, iparams, exparams):\n",
    "        p=params\n",
    "        u=y['u']\n",
    "        v=y['v']\n",
    "        dudt = p['D']*laplace(u)-(10.0**p['logk'])*u*(u-p['a'])*(u-1) - u*v\n",
    "        dvdt = epsilon(u,v,p)*(-v-(10.0**p['logk'])*u*(u-p['a']-1))\n",
    "        return {'u':dudt, 'v':dvdt}\n",
    "    \n",
    "  def gen_params():\n",
    "    return {'D':1.5,'a':0.06,'logk':1.0,'eps0':0.001,'mu1':0.2,'mu2':0.3}, {}, {}\n",
    "\n",
    "  def loss(ys, params, iparams, exparams, targets):\n",
    "    flat_fit = ys['u']\n",
    "    flat_target = targets['u']\n",
    "    return jnp.nanmean((flat_fit - flat_target)**2)  \n",
    "        \n",
    "  return eom, loss, gen_params, None, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use previous data to generate truth for AP model\n",
    "ys_BOCF = dataset_BOCF.ys\n",
    "y0 = {'u':ys_BOCF['u'][:,0], 'v':ys_BOCF['v'][:,0]}\n",
    "target_ys = {'u':ys_BOCF['u'], 'v':ys_BOCF['v']}\n",
    "t_evals = dataset_BOCF.t_evals/12.9 # The implementations have different timescales, BOCF is in ms while AP in a typically non-dimensionalized unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_guess = {'D':1.17,'a':0.06,'logk':1.0,'eps0':0.001,'mu1':0.2,'mu2':0.3}\n",
    "kwargs_sys = {'disc_x': 128,\n",
    "            'disc_y': 128,\n",
    "            'len_x': 128,\n",
    "            'len_y': 128,\n",
    "            'N_sys': 1}\n",
    "kwargs_adoptODE = {\n",
    "    'epochs': 200,\n",
    "    'lr': 5e-3,\n",
    "    'lr_y0':5e-3,\n",
    "    'N_backups': 2,\n",
    "    'atol': 1e-5,\n",
    "    'rtol': 1e-5,\n",
    "    'lower_b':tree_util.tree_map(lambda x: 0*x+1e-4, params_guess),\n",
    "    'lower_b_y0':{'u':y0['u'], 'v':0},\n",
    "    'upper_b_y0':{'u':y0['u'], 'v':10}\n",
    "} # lower bound\n",
    "target_ys = {'u':ys_BOCF['u'], 'v':ys_BOCF['v']}\n",
    "dataset_AP = dataset_adoptODE(define_AP, target_ys, t_evals, kwargs_sys, kwargs_adoptODE, params_train = params_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000:  Loss: 1.5e-01,  Params Err.: nan, y0 error: nan, Params Norm: 1.6e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 010:  Loss: 1.4e-01,  Params Err.: nan, y0 error: nan, Params Norm: 1.6e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 020:  Loss: 1.1e-01,  Params Err.: nan, y0 error: nan, Params Norm: 1.6e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 030:  Loss: 8.3e-02,  Params Err.: nan, y0 error: nan, Params Norm: 1.6e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 040:  Loss: 7.4e-02,  Params Err.: nan, y0 error: nan, Params Norm: 1.6e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 050:  Loss: 6.5e-02,  Params Err.: nan, y0 error: nan, Params Norm: 1.7e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 060:  Loss: 5.7e-02,  Params Err.: nan, y0 error: nan, Params Norm: 1.7e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 070:  Loss: 5.2e-02,  Params Err.: nan, y0 error: nan, Params Norm: 1.7e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 080:  Loss: 4.8e-02,  Params Err.: nan, y0 error: nan, Params Norm: 1.8e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 090:  Loss: 4.5e-02,  Params Err.: nan, y0 error: nan, Params Norm: 1.8e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 100:  Loss: 4.2e-02,  Params Err.: nan, y0 error: nan, Params Norm: 1.9e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 110:  Loss: 3.8e-02,  Params Err.: nan, y0 error: nan, Params Norm: 1.9e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 120:  Loss: 3.4e-02,  Params Err.: nan, y0 error: nan, Params Norm: 2.0e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 130:  Loss: 3.1e-02,  Params Err.: nan, y0 error: nan, Params Norm: 2.1e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 140:  Loss: 2.7e-02,  Params Err.: nan, y0 error: nan, Params Norm: 2.2e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 150:  Loss: 2.3e-02,  Params Err.: nan, y0 error: nan, Params Norm: 2.2e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 160:  Loss: 2.0e-02,  Params Err.: nan, y0 error: nan, Params Norm: 2.3e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 170:  Loss: 1.7e-02,  Params Err.: nan, y0 error: nan, Params Norm: 2.4e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 180:  Loss: 1.5e-02,  Params Err.: nan, y0 error: nan, Params Norm: 2.5e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 190:  Loss: 1.3e-02,  Params Err.: nan, y0 error: nan, Params Norm: 2.5e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n",
      "Epoch 199:  Loss: 1.2e-02,  Params Err.: nan, y0 error: nan, Params Norm: 2.6e+00, iParams Err.: 0.0e+00, iParams Norm: 0.0e+00, \n"
     ]
    }
   ],
   "source": [
    "params_final, losses, errors, params_history = train_adoptODE(dataset_AP, print_interval=10, save_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92199ba341894963afbe2811e5e726f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Frame', max=99)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd636b0cae9e45818e55616d7ad61fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pad = 10\n",
    "dA = compute_dA(dataset_BOCF.ys['x'][0],1)\n",
    "# Function to update the plot\n",
    "def update_plot(frame):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))  # Create 2 side-by-side subplots\n",
    "    \n",
    "    # Plot dA_fit\n",
    "    im1 = axes[0].matshow(dataset_AP.ys['u'][0,frame], cmap='coolwarm')\n",
    "    # im1 = axes[0].matshow(dA_rec[frame, pad:-pad, pad:-pad], cmap='coolwarm', vmin=vmin, vmax=vmax)\n",
    "    axes[0].set_title(f\"simulation\")\n",
    "    \n",
    "    # Plot dA_sim\n",
    "    im2 = axes[1].matshow(dataset_AP.ys_sol['u'][0,frame], cmap='coolwarm')\n",
    "    # im2 = axes[1].matshow(dA_sim[frame, pad:-pad, pad:-pad], cmap='coolwarm', vmin=vmin, vmax=vmax)\n",
    "    axes[1].set_title(f\"reconstruction\")\n",
    "    \n",
    "    # Add colorbars\n",
    "    # fig.colorbar(im1, ax=axes[0])\n",
    "    # fig.colorbar(im2, ax=axes[1])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive slider\n",
    "frame_slider = widgets.IntSlider(min=0, max=dataset_BOCF.ys['u'][0,:].shape[0]-1, step=1, value=0, description=\"Frame\")\n",
    "\n",
    "# Use interactive_output instead of interactive\n",
    "out = widgets.interactive_output(update_plot, {'frame': frame_slider})\n",
    "\n",
    "# Display slider and output\n",
    "display(frame_slider, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file_path = (f\"../data/SpringMassModel/MechanicalData/MSD_BOCF\")\n",
    "\n",
    "# with h5py.File(file_path, 'w') as f:\n",
    "#     group = f.create_group('datasetBOCF_MSD_AP_fit')  # Create a group instead of a dataset\n",
    "#     group.create_dataset('u_sol_AP', data=dataset_AP.ys_sol['u'])\n",
    "#     group.create_dataset('u_BOCF',data=dataset_AP.ys['u'])\n",
    "#     group.create_dataset('v_sol', data=dataset_AP.ys_sol['v'])\n",
    "#     group.create_dataset('v_BOCF',data=dataset_AP.ys['v'])\n",
    "#     group.create_dataset('u_sol', data=dataset_AP.ys_sol['u'])\n",
    "#     group.create_dataset('u',data=dataset_AP.ys['u'])\n",
    "#     group.create_dataset('T', data=dataset_BOCF.ys['T'])\n",
    "#     group.create_dataset('x',data=dataset_BOCF.ys['x'])\n",
    "#     group.create_dataset('x_dot',data=dataset_BOCF.ys['x_dot'])\n",
    "#     params = group.create_group(\"params_train_AP\")  # Create a subgroup\n",
    "#     for key, value in dataset_AP.params_train.items():\n",
    "#         params.attrs[key] = value  # Store values as attributes\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate with Aliev Pafielov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_MSD_rec(**kwargs_sys):\n",
    "    N_sys = kwargs_sys['N_sys']\n",
    "\n",
    "    def gen_params():\n",
    "        iparams = {'testpar':0}\n",
    "        params = {key:value + kwargs_sys['par_tol']*value*np.random.uniform(-1.0, 1.0) for key,value in kwargs_sys['params_true'].items()}\n",
    "        iparams = {key:jnp.array([value + kwargs_sys['par_tol']*value*np.random.uniform(-1.0, 1.0) for _ in range(kwargs_sys['N_sys'])]) for key,value in kwargs_sys['params_true'].items()}\n",
    "        # iparams = {key:np.full(kwargs_sys['N_sys'],[value + kwargs_sys['par_tol']*value*np.random.uniform(-1.0, 1.0)]) for key,value in kwargs_sys['params_true'].items()}\n",
    "        return  params,{}, {}\n",
    "    \n",
    "    def gen_y0():\n",
    "        return {'u':kwargs_sys['u0'],'v':kwargs_sys['v0'],'T':kwargs_sys['T0'],'x':kwargs_sys['x0'],'x_dot':kwargs_sys['x_dot0']}\n",
    "    @jit\n",
    "    def kernel(spacing):\n",
    "        kernel = np.array([[1, 4, 1], [4, -20.0, 4], [1, 4, 1]]) / (spacing* spacing * 6)\n",
    "        return kernel\n",
    "    @jit\n",
    "    def laplace(f,params):  #laplace of scalar\n",
    "        f_ext = jnp.concatenate((f[0:1], f, f[-1:]), axis=0)\n",
    "        f_ext = jnp.concatenate((f_ext[:, 0:1], f_ext, f_ext[:, -1:]), axis=1)\n",
    "        return convolve2d(f_ext, kernel(params['spacing']), mode='valid')\n",
    "    @jit\n",
    "    def epsilon(u,v,rp):\n",
    "        return rp['epsilon_0']+rp['mu_1']*v/(u+rp['mu_2'])\n",
    "    @jit\n",
    "    def epsilon_T(u):\n",
    "        return 1 - 0.9*jnp.exp(-jnp.exp(-30*(jnp.abs(u) - 0.1)))\n",
    "    \n",
    "    @jit\n",
    "    def eom(y, t, params, iparams, exparams):\n",
    "            par=params\n",
    "            u=y['u']\n",
    "            v=y['v']\n",
    "            T=y['T']\n",
    "            x=y['x']\n",
    "            x_dot=y['x_dot']\n",
    "\n",
    "            dudt = par['D']*laplace(u,par)-(par['k'])*u*(u-par['a'])*(u-1) - u*v\n",
    "            dvdt = epsilon(u,v,par)*(-v-(par['k'])*u*(u-par['a']-1))\n",
    "            dTdt = epsilon_T(u)*(par['k_T']*jnp.abs(u)-T)\n",
    "            dx_dotdt = 1/par['m'] *  (force_field_active(x,T,par) + force_field_passive(x,par) + force_field_struct(x,T,par) - x_dot * par['c_damp'])\n",
    "            dxdt = x_dot\n",
    "\n",
    "            return {'u':dudt, 'v':dvdt, 'T':dTdt, 'x':zero_out_edges(dxdt), 'x_dot':zero_out_edges(dx_dotdt)}\n",
    "    \n",
    "    @jit\n",
    "    def loss(ys, params, iparams, exparams, targets):\n",
    "        # u = ys['u']\n",
    "        # u_target = targets['u']\n",
    "        pad = 10\n",
    "        x = ys['x'][:,:,pad:-pad,pad:-pad]\n",
    "        x_target = targets['x'][:,:,pad:-pad,pad:-pad]\n",
    "        x_dot = ys['x_dot'][:,:,pad:-pad,pad:-pad]\n",
    "        x_dot_target = targets['x_dot'][:,:,pad:-pad,pad:-pad]\n",
    "        u_target = targets['u']\n",
    "        u = ys['u']\n",
    "        return  jnp.nanmean((x - x_target)**2 + (x_dot-x_dot_target)**2)#+ jnp.nanmean((u - u_target)**2)\n",
    "            \n",
    "    return eom, loss, gen_params, None, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def load_run(file_path, run):\n",
    "    '''Reads the data and parameters from a saved HDF5 file'''\n",
    "    \n",
    "    data = {}  # Dictionary to store datasets\n",
    "    params_dict = {}  # Dictionary to store parameters\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        if run not in f:\n",
    "            raise ValueError(f\"Run '{run}' not found in file.\")\n",
    "        \n",
    "        group = f[run]  # Access the group corresponding to the given 'run'\n",
    "        \n",
    "        # Load all datasets (convert to NumPy arrays)\n",
    "        for key in ['u_sol', 'u', 'v_sol', 'v', 'T_sol', 'T', 'x_sol', 'x']:\n",
    "            if key in group:\n",
    "                data[key] = np.array(group[key])  # Convert dataset to NumPy array\n",
    "        \n",
    "        # Load parameter attributes from 'params_train' subgroup\n",
    "        if \"params_train\" in group:\n",
    "            params_group = group[\"params_train\"]\n",
    "            for key in params_group.attrs:\n",
    "                params_dict[key] = params_group.attrs[key]  # Store as dictionary\n",
    "    \n",
    "    return data, params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ HDF5 File: ../data/SpringMassModel/MechanicalData/MSD_BOCF\n",
      "üìÇ Group: datasetBOCF_MSD_AP_fit\n",
      "  üìÇ Group: datasetBOCF_MSD_AP_fit/params_train_AP\n",
      "<KeysViewHDF5 ['T', 'params_train_AP', 'u', 'u_BOCF', 'u_sol', 'u_sol_AP', 'v_BOCF', 'v_sol', 'x', 'x_dot']>\n",
      "{'D': np.float32(2.1702752), 'a': np.float32(0.0663672), 'eps0': np.float32(1e-04), 'logk': np.float32(1.0454719), 'mu1': np.float32(0.9758727), 'mu2': np.float32(0.1895892)}\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/SpringMassModel/MechanicalData/MSD_BOCF'\n",
    "list_h5_structure(file_path)\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    data = f['datasetBOCF_MSD_AP_fit']  # Access the group corresponding to the given 'run'\n",
    "    print(data.keys())\n",
    "# Load the data and parameters from the HDF5 file\n",
    "\n",
    "\n",
    "\n",
    "# Accessing the datasets\n",
    "    params_AP = {}\n",
    "    u_AP = data['u_sol_AP'][0]\n",
    "    u_sim = data['u_BOCF'][0]\n",
    "    v_AP = data['v_sol'][0]\n",
    "    v_sim = data['v_BOCF'][0]\n",
    "    T_sim = data['T'][0]\n",
    "    x_sim = data['x'][0]\n",
    "    x_dot_sim = data['x_dot'][0]\n",
    "    params_group = data['params_train_AP']\n",
    "    for key in params_group.attrs:\n",
    "        params_AP[key] = params_group.attrs[key]  # Store as dictionary\n",
    "targets = {}\n",
    "print(params_AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kwargs_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m kwargs_sys \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      2\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_sys\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpar_tol\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m.5\u001b[39m,\n\u001b[1;32m      4\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams_true\u001b[39m\u001b[38;5;124m'\u001b[39m: params_true,\n\u001b[0;32m----> 5\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_gaussians\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mkwargs_training\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_gaussians\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m      6\u001b[0m kwargs_adoptODE \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_backups\u001b[39m\u001b[38;5;124m'\u001b[39m: kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_backups\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m:kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower_b\u001b[39m\u001b[38;5;124m'\u001b[39m: params_low,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper_b\u001b[39m\u001b[38;5;124m'\u001b[39m: params_high,\n\u001b[1;32m      8\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_y0\u001b[39m\u001b[38;5;124m'\u001b[39m:kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_y0\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m                 \u001b[38;5;66;03m# 'lr_ip': kwargs_training['lr_ip'],\u001b[39;00m\n\u001b[1;32m     10\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower_b_y0\u001b[39m\u001b[38;5;124m'\u001b[39m:{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m:kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu_low\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m:kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_low\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m:kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_low\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m:x0,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_dot\u001b[39m\u001b[38;5;124m'\u001b[39m:x_dot0},\n\u001b[1;32m     11\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper_b_y0\u001b[39m\u001b[38;5;124m'\u001b[39m:{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m:kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu_high\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m:kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_high\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m:kwargs_training[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_high\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m:x0,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_dot\u001b[39m\u001b[38;5;124m'\u001b[39m:x_dot0}}\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_measurement_constraint\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs_training:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kwargs_training' is not defined"
     ]
    }
   ],
   "source": [
    "kwargs_sys = {'size': 100,\n",
    "                'N_sys':1,\n",
    "                'par_tol': .5,\n",
    "                'params_true': params_true}\n",
    "kwargs_adoptODE = {'epochs': 10,'N_backups': 1,'lr':2e-3,\n",
    "                'lower_b': params_low,'upper_b': params_high,\n",
    "                'lr_y0':2e-3,\n",
    "                # 'lr_ip': kwargs_training['lr_ip'],\n",
    "                'lower_b_y0':{'u':0,'v':0,'T':0,'x':x0-x0*.1,'x_dot':x_dot0+x_dot0*.1},\n",
    "                'upper_b_y0':{'u':1,'v':10,'T':['T_high'],'x':x0+x0*.1,'x_dot':x_dot0+x_dot0*.1}}\n",
    "\n",
    "dataset_MSD = dataset_adoptODE(define_MSD_rec,\n",
    "                                targets,\n",
    "                                t_evals, \n",
    "                                kwargs_sys,\n",
    "                                kwargs_adoptODE,\n",
    "                                true_params=params_true)#,\n",
    "                                #true_iparams=params_true)\n",
    "return dataset_MSD,Simulation_MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
